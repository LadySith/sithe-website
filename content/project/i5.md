+++
# Date this page was created.
date = "2018-03-17"

# Project title.
title = "i5 Space Glove"

# Project summary to display on homepage.
summary = "i5 Space Glove created for the NASA Space Apps Challenge 2015."

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "spaceglove.jpg"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["maker", "makey makey", "NASA Space Apps Challenge"]

# Optional external URL for project (replaces project detail page).
external_link = ""

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
image = ""
caption = ""

+++

{{< youtube N93fMMkzY_E >}}

## Background

The command interface to our computers has moved away from keyboard and mouse, to touchscreens, gesture and voice activation. These advances are now in commercial consumer technology and could be applied to a manned space mission to improve the human-machine interface.

Existing smartphone devices and other wearable technology contain accelerometers and other positioning sensors that could be used as a command interface when combined with gesture. Wearing such a device would also allow the user to access the built-in functions and applications of the device. For example, applications could be split or shared between the main computer and the wearable device, thereby allowing them to be mobile and moved around the spacecraft.

## Challenge

This challenge seeks to change the way crew members and operators interact with computer systems using gestures and voice control. The user wears a number of devices on their person, e.g. one on each wrist, which will allow them to control an application running on a linked (e.g. via wireless technology) computer.

Weâ€™d like you to produce a new technique for controlling a computer application via one or more wearable devices (e.g. smartphone) that wirelessly connects to the main computer and responds to gestures and voice commands. Create unique ways for data and applications to be swiped/transferred between the wearable devices and the main computer. Arm and hand gestures can be used as a control interface to the main computer replacing traditional mouse or touch interaction. In addition, voice commands can be used as an input. The two should be able to work in concert with each other, or independently, should one input mode fail.
